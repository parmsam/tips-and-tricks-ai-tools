# Considerations

## Understanding

AI assistants shouldn't replace good understanding of your code and selected programming language. Developers should be aware of [common failures](https://arxiv.org/abs/2302.03494) of systems they may be using. You should also be cautious about use of tools like [ChatGPT to avoid learning](https://youtu.be/IgxzcOugvEI?t=214).

## Sensitive data

Ensure that you don't provide AI code assistants such as ChatGPT or Github CoPilot with sensitive code or data. There have been many cases of [employees pasting sensitive data](https://www.darkreading.com/risk/employees-feeding-sensitive-business-data-chatgpt-raising-security-fears), with some [estimates of how common this is](https://www.cyberhaven.com/blog/4-2-of-workers-have-pasted-company-data-into-chatgpt/). Consider reading the privacy policy for the AI assistant that you're using and ensure sensitive data is kept separate from such systems.

## Plagiarism

Consider risk of unintentional plagiarism or copyright violation associated with overuse of tools like ChatGPT. The [story of sumplete](https://www.digitaltrends.com/gaming/sumplete-chatgpt-ai-game-design-ethics/), [numerous ongoing lawsuits](https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data), and numerous [ethical issues](https://arxiv.org/abs/2305.10646) show us that these tools should used with care.

## Trust by verify

Just because something sounds right, doesn't mean it is right. Sometimes AI tools provide incorrect answers, so it's your responsibility to check the results, as recommended [in Nature](https://www.nature.com/articles/d41586-023-01833-0). Check if there are any bugs or hallucinations (such as functions that don't exist) in code you obtain and confirm you understand what each lines is doing. You can use AI tools to support this verification process but you should be an active part of it. Use unit testing and assertive programming to ensure results perform as expected in the cases you need to cover.

## Iterate on it

As noted [in Nature](https://www.nature.com/articles/d41586-023-01833-0), Sometimes you'll need to have a conversation with an AI tool to get what you want (this is called [prompt chaining](https://www.voiceflow.com/blog/prompt-chaining-conversational-ai)). You might even need to start all over again. It often doesn't work on the first try. Try changing your approach. Consider changing settings for the tool you're using like temperature in ChatGPT. Try using different tools.

## List out multiple possibilities

Ask the platform to list out multiple different options. You can specify how many results you want to be generated. You can serve as the curator deciding what is useful vs. throwaway information.

## Use seperators

Consider using separators like quotation marks (`""` or `''`) or backticks (\`) to separate sections of text that should get treated differently in the prompt, as indicated from [the-decoder](https://the-decoder.com/chatgpt-guide-prompt-strategies/).

## Summarize the conversation

Ask the AI tools to summarize the conversation at completion. This can help recap the tasks accomplished and reflect on what could have been done better.

## Keep it simple

Break your problem into small pieces or tasks, as suggested [in Nature](https://www.nature.com/articles/d41586-023-01833-0). This is similar to the [strategy you should use](https://www.indeed.com/career-advice/career-development/how-to-break-down-project-into-tasks) when working on any complex project. Keeping it simple is a good rule of thumb here. As mentioned before, [*prompt chaining* or *chained prompting*](https://www.voiceflow.com/blog/prompt-chaining-conversational-ai) can be used to solve more complex problems.

## Be specific

Be a good designer and keep your prompts specific and clear. As part of that, you can include the response format or an example response you expect to receive. You could add a word limit or readability level (keep responses at a middle school level for example). You could mention the target audience, desired tone, or a [persona](https://www.howtogeek.com/881659/how-to-create-chatgpt-personas-for-every-occasion/) the tool should adopt. There are a lot of these different *response settings* you can define to mold the responses. Some experimentation is required here, but that's the fun part.

## Be aware of limitations

You should consider the training cutt-off dates for the LLM models that you are using. The training cutoff date for OpenAI's GPT-3.5 and GPT-4 models is September 2021. This may limit the ability include more recent information in chat results. Other platforms like Bing and Bard can have more recent results since they can search the internet.

## Adhere to Simon Willison's Personal AI Ethics

Simon Willison had a great talk in August 2023 on [Making Large Language Models work for you](https://simonwillison.net/2023/Aug/27/wordcamp-llms/). In the talk, he shared his personal AI ethical guidelines which included the following (watch [the talk](https://www.youtube.com/watch?v=LpDulftMkew&t=29900s&ab_channel=WordPress) to learn why):

- Don't publish anything that will take someone longer to read than it took you to write. 
- Never commit code you can't understand and explain every line of.
- Share your prompts and help spread knowledge of how to use these tools
- Be aware of the harm of these AI tools to believable mimic humans. Instead of responses that mimic humans, ask tools like ChatGPT to be a sentient cheesecake or a Shakespearean coal miner. The response are way better, safer, and more entertaining.



